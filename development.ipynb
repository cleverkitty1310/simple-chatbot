{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\WhiteWolf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\WhiteWolf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\WhiteWolf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'context': '',\n",
       "   'patterns': ['Hello', 'Hi there', 'Good morning', \"What's up\"],\n",
       "   'responses': ['Hey!', 'Hello', 'Hi!', 'Good morning'],\n",
       "   'tag': 'hello'},\n",
       "  {'context': [''],\n",
       "   'patterns': [],\n",
       "   'responses': [\"Sorry, can't understand you\",\n",
       "    'Please give me more info',\n",
       "    'Not sure I understand'],\n",
       "   'tag': 'noanswer'},\n",
       "  {'context': '',\n",
       "   'patterns': ['What is your job', 'What is your work'],\n",
       "   'responses': ['My job is to make you feel like everythin is okay.',\n",
       "    'I work to serve you as well as possible.'],\n",
       "   'tag': 'job'},\n",
       "  {'context': '',\n",
       "   'patterns': ['What is your age', 'How old are you', 'When were you born'],\n",
       "   'responses': ['I was born in 2022'],\n",
       "   'tag': 'age'},\n",
       "  {'context': '',\n",
       "   'patterns': ['What is your name',\n",
       "    'May I have your name',\n",
       "    'Tell me your name'],\n",
       "   'responses': ['My name is Kitty', 'I am Kitty'],\n",
       "   'tag': 'name'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = open('./intents.json')\n",
    "data = json.load(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens = nltk.word_tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        data_X.append(pattern)\n",
    "        data_y.append(intent[\"tag\"])\n",
    "\n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
    "\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "\n",
    "for idx, doc in enumerate(data_X):\n",
    "    bow = []\n",
    "    text = lemmatizer.lemmatize(doc.lower())\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(data_y[idx])] = 1\n",
    "    training.append([bow, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_Y = np.array(list(training[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               3456      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,037\n",
      "Trainable params: 12,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.6609 - accuracy: 0.1667\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5470 - accuracy: 0.2500\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4160 - accuracy: 0.4167\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3787 - accuracy: 0.3333\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4614 - accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0869 - accuracy: 0.8333\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0051 - accuracy: 0.6667\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.8333\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8853 - accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7606 - accuracy: 0.6667\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6100 - accuracy: 0.8333\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5034 - accuracy: 0.8333\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3403 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.9167\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8333\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5427 - accuracy: 0.9167\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2665 - accuracy: 0.9167\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2725 - accuracy: 0.9167\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4415 - accuracy: 0.7500\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2801 - accuracy: 0.8333\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0564 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1597 - accuracy: 0.9167\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0969 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3228 - accuracy: 0.9167\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0972 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1149 - accuracy: 0.9167\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2696 - accuracy: 0.8333\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1636 - accuracy: 0.9167\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2571 - accuracy: 0.9167\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3784 - accuracy: 0.8333\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0639 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0510 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1095 - accuracy: 0.9167\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1113 - accuracy: 0.9167\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9167\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.9730e-04 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4935e-04 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7401e-04 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.9454e-04 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.1278e-04 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3783e-04 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3467 - accuracy: 0.8333\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.0239e-04 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.7731e-04 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5611e-04 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4884e-04 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2932e-04 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5063e-04 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8201e-04 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1808e-04 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1108 - accuracy: 0.9167\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0987 - accuracy: 0.9167\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4461e-04 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7936e-04 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8244e-04 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7065e-04 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6561e-04 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3424e-04 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.4006e-04 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.9328e-04 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4169e-05 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.8821e-05 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9038e-04 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8677e-07 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0411e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2177e-04 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5329e-04 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0779e-04 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1321e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9343e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2118e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1884e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed4b1273a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_X[0]), ), activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_Y[0]), activation=\"softmax\"))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "model.fit(x=train_X, y=train_Y, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def bag_of_words(text, vocab):\n",
    "    tokens = clean_text(text)\n",
    "    bow = [0] * len(vocab)\n",
    "    for w in tokens:\n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word == w:\n",
    "                bow[idx] = 1\n",
    "    return np.array(bow)\n",
    "\n",
    "def pred_class(text, vocab, labels):\n",
    "    bow = bag_of_words(text, vocab)\n",
    "    result = model.predict(np.array([bow]), verbose=0)[0]\n",
    "    thresh = 0.5\n",
    "    y_pred = [[indx, res] for indx, res in enumerate(result) if res > thresh]\n",
    "    y_pred.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in y_pred:\n",
    "        return_list.append(labels[r[0]])\n",
    "    return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    if len(intents_list) == 0:\n",
    "        result = \"Sorry! I don't understand.\"\n",
    "    else:\n",
    "        tag = intents_list[0]\n",
    "        list_of_intents = intents_json[\"intents\"]\n",
    "        for i in list_of_intents:\n",
    "            if i[\"tag\"] == tag:\n",
    "                result = random.choice(i[\"responses\"])\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 0 if you don't want to chat with my ChatBot.\n",
      "I am Kitty\n",
      "My name is Kitty\n",
      "My name is Kitty\n",
      "Hi!\n",
      "I am Kitty\n",
      "I was born in 2022\n"
     ]
    }
   ],
   "source": [
    "print(\"Press 0 if you don't want to chat with my ChatBot.\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "        break\n",
    "    intents = pred_class(message, words, classes)\n",
    "    result = get_response(intents, data)\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1aac92cf110ca7a693f9013b870bc15ddd1e6dae170b412350fd8c0dda8cd7c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
